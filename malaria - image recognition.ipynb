{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data source: https://ceb.nlm.nih.gov/repositories/malaria-datasets/\n",
    "# The dataset contains a total of 27,558 cell images with equal instances of parasitized and uninfected cells.\n",
    "%reset -f\n",
    "\n",
    "from keras.models import Sequential # to initialize CNN as a sequence of layers\n",
    "from keras.layers import Convolution2D # for convolutional operations\n",
    "from keras.layers import MaxPooling2D # for pooling operations\n",
    "from keras.layers import Flatten # to flatten stacked feature maps into input layer\n",
    "from keras.layers import Dense # to build fully-connected layers in a traditional neural network\n",
    "from keras.layers import Dropout # to build a dropout layer(s); helps prevent overfitting\n",
    "from keras.layers import BatchNormalization # to avoid internal covariate shift and speed up training\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### set some hyperparameters\n",
    "num_epochs = 3\n",
    "batchsize = 128\n",
    "rescaled_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### part 1: building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### initialize the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### step 1: add a convolution layer to the CNN\n",
    "classifier.add(Convolution2D(filters=32, # 32 filters/kernels\n",
    "                             kernel_size=(3,3), # each kernel has a 3x3 receptive field\n",
    "                             padding='same', # spatial dimensions of input image and feature map are the same\n",
    "                             input_shape=(64,64,3), # each input image has width=height=64, and 3 color channels\n",
    "                             strides=(1,1), # stride 1 pixel at a time, along the width and height\n",
    "                             activation='relu')) # apply ReLU activation function to the conv layer element-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### step 2: add a pooling layer to the CNN\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2), # pooling kernel has a 2x2 receptive field\n",
    "                            strides=(2,2))) # stride 2 pixels at a time, along the width and height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### step 3: add a batch normalization layer to the CNN\n",
    "classifier.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### step 4: repeat steps 1 to 3 for a deep CNN\n",
    "classifier.add(Convolution2D(filters=32, # 32 filters\n",
    "                             kernel_size=(3,3), # each kernel has a 3x3 receptive field\n",
    "                             padding='same', # spatial dimensions of input image and feature map are the same\n",
    "                             strides=(1,1), # stride 1 pixel at a time, along the width and height\n",
    "                             activation='relu')) # apply ReLU activation function to the conv layer element-wise\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2), # pooling kernel has a 2x2 receptive field\n",
    "                            strides=(2,2))) # stride 2 pixels at a time, along the width and height\n",
    "\n",
    "classifier.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### step 5: flatten the pooled feature maps into a vector of neurons (to be used as an input layer in a classic NN)\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### step 6: fully connect the input layer to a hidden layer and output layer (classic NN)\n",
    "classifier.add(Dropout(0.5)) # dropout layer (with 50% probability of shutting down any given neuron) prevents overfitting\n",
    "\n",
    "classifier.add(Dense(units=128, # 128 neurons in the hidden layer\n",
    "                     activation='relu'))\n",
    "\n",
    "classifier.add(Dropout(0.5)) # dropout layer (with 50% probability of shutting down any given neuron) prevents overfitting\n",
    "\n",
    "classifier.add(Dense(units=1, # classification problem is binary\n",
    "                     activation='sigmoid')) # if classification problem was multiclass, we'd use softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### compile the CNN\n",
    "classifier.compile(optimizer='adam', # stochastic gradient descent algorithm (to optimize the weights)\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy']) # alternative: crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### part 2: fitting the CNN to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17558 images belonging to 2 classes.\n",
      "Found 10000 images belonging to 2 classes.\n",
      "Epoch 1/3\n",
      "138/138 [==============================] - 527s 4s/step - loss: 0.6028 - acc: 0.6907 - val_loss: 1.1226 - val_acc: 0.7068\n",
      "Epoch 2/3\n",
      "138/138 [==============================] - 516s 4s/step - loss: 0.3933 - acc: 0.8359 - val_loss: 0.9427 - val_acc: 0.8148\n",
      "Epoch 3/3\n",
      "138/138 [==============================] - 546s 4s/step - loss: 0.2350 - acc: 0.9195 - val_loss: 0.7617 - val_acc: 0.8370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x156ef5049b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### prevent overfitting by augmenting the number of images with transformed (e.g. zoomed, sheared) versions of those images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "os.chdir('D:\\cell_images')\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('training_set',\n",
    "                                                 target_size=(rescaled_size,rescaled_size), # all images will be resized to 64x64 pixels\n",
    "                                                 batch_size=batchsize, # weights are updated every time batchsize images have been fed into the CNN\n",
    "                                                 class_mode='binary') # 'categorical' if multiclass classification\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('test_set',\n",
    "                                            target_size=(rescaled_size,rescaled_size),\n",
    "                                            batch_size=batchsize,\n",
    "                                            class_mode='binary')\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         epochs=num_epochs, # number of times you want to feed all the training images into the CNN\n",
    "                         validation_data=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save model\n",
    "#classifier.save('flowers - model.h5')\n",
    "\n",
    "### load model\n",
    "#from keras.models import load_model\n",
    "#classifier = load_model('flowers - model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
